{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb369bdb-83c5-4403-83c5-043cdd6b1c09",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169c2df4-1dd1-4b70-a6b2-a7723afe147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as components\n",
    "import requests\n",
    "import kfp.dsl as dsl\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import kubernetes as k8s\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import BucketAlreadyOwnedByYou\n",
    "    \n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_URL = \"minio-service.kubeflow.svc.cluster.local:9000\"\n",
    "MINIO_USER = \"minio\"\n",
    "MINIO_PASS = \"minio123\"\n",
    "MINIO_SECURE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6fd38b-be2d-4559-94ee-6de7d83660d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image = \"public.ecr.aws/x6u1q5c1/kflow/pytorch:cpu-1.13.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbebb74-6090-432f-abce-0a946ef0c3b6",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc72a2e7-f1a6-4566-bb5f-480d9e3e3089",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7509e5a-5e7f-44ac-9bf2-5711d968d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(minio_args, bucket_name):\n",
    "    \"\"\"\n",
    "    Function to get dataset and load it to minio bucket\n",
    "    \"\"\"\n",
    "    print(\"initializing\")\n",
    "    from minio import Minio\n",
    "    import urllib.request\n",
    "    \n",
    "    print(\"getting data\")\n",
    "    urllib.request.urlretrieve(\"http://*/intel.zip\", \"/tmp/intel.zip\")\n",
    "    \n",
    "    print(\"uploading data\")\n",
    "    minio_client = Minio(**minio_args)\n",
    "    if minio_client.bucket_exists(bucket_name)==False:\n",
    "        print('creating bucket')\n",
    "        minio_client.make_bucket(bucket_name)\n",
    "    minio_bucket = bucket_name\n",
    " \n",
    "    minio_client.fput_object(minio_bucket,\"intel.zip\",\"/tmp/intel.zip\")\n",
    "    \n",
    "    dataset_version = \"1.0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4aa9e1-eb0c-47b3-b497-0df66b43f696",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94a9c5b-e191-4ad5-bf10-2f2f54bd4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(minio_args, bucket_name) -> NamedTuple('Outputs', [('class_labels', str),('total_count', int),('train_count', int),('test_count', int)]):\n",
    "    \"\"\"\n",
    "    Preprocessing the data for model building\n",
    "    \"\"\"\n",
    "    print(\"preprocessing data\")\n",
    "    \n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    from zipfile import ZipFile\n",
    "    from pathlib import Path\n",
    "    from collections import Counter\n",
    "    import json\n",
    "    import shutil\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from collections import namedtuple\n",
    "\n",
    "    def write_dataset(image_paths, output_dir):\n",
    "        for img_path in image_paths:\n",
    "            Path(output_dir / img_path.parent.stem).mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copyfile(img_path, output_dir / img_path.parent.stem / img_path.name)\n",
    "\n",
    "    minio_client = Minio(**minio_args)\n",
    "    minio_bucket = bucket_name\n",
    "    \n",
    "    # load data from minio\n",
    "    print(\"fetching data\")\n",
    "    minio_client.fget_object(minio_bucket,\"intel.zip\",\"/tmp/intel.zip\")    \n",
    "    \n",
    "    print(\"extracting data\")\n",
    "    with ZipFile(\"/tmp/intel.zip\", 'r') as zObject:\n",
    "        zObject.extractall(path=\"/tmp/\")\n",
    "        \n",
    "    dataset_full = list(Path(\"/tmp/intel\").glob(\"*/*.jpg\"))\n",
    "    labels = [x.parent.stem for x in dataset_full]\n",
    "\n",
    "    d_train, d_test = train_test_split(dataset_full, stratify=labels)\n",
    "\n",
    "    print(\"writing data splits\")\n",
    "    write_dataset(d_train, Path(\"/tmp/dataset/train\"))\n",
    "    write_dataset(d_test, Path(\"/tmp/dataset/test\"))\n",
    "    \n",
    "    print(\"compressing data splits\")\n",
    "    shutil.make_archive(\"/tmp/train\", 'zip', \"/tmp/dataset/train\")\n",
    "    shutil.make_archive(\"/tmp/test\", 'zip', \"/tmp/dataset/test\")\n",
    "    \n",
    "    # save data from minio\n",
    "    print(\"uploading data splits\")\n",
    "    minio_client.fput_object(minio_bucket,\"train.zip\",\"/tmp/train.zip\")\n",
    "    minio_client.fput_object(minio_bucket,\"test.zip\",\"/tmp/test.zip\")\n",
    "    \n",
    "    divmod_output = namedtuple('Outputs', ['class_labels', 'total_count', 'train_count', 'test_count'])\n",
    "    return [', '.join([str(elem) for elem in sorted(set(labels))]), len(dataset_full), len(d_train), len(d_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f97fd-8750-4e31-b601-c240e33e8765",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e89cc3-513d-4fb3-a3cc-d7e19f6dc08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ptkflow'...\n",
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 4 (delta 0), reused 4 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (4/4), 45.38 KiB | 5.04 MiB/s, done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<minio.helpers.ObjectWriteResult at 0x7fcd27307f40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !git clone https://github.com/mmg10/ptkflow\n",
    "# minio_client.fput_object(\"pytorch\",\"traincode.zip\",\"./ptkflow/traincode.zip\")\n",
    "# minio_client.fput_object(\"pytorch\",\"convertcode.zip\",\"./ptkflow/convertcode.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "329c147a-5695-4a92-8f6e-65314ea79299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(\n",
    "    no_epochs,\n",
    "    accelerator,\n",
    "    minio_args,\n",
    "    bucket_name\n",
    "    ) -> NamedTuple('Output', [('mlpipeline_ui_metadata', 'UI_metadata'),('mlpipeline_metrics', 'Metrics')]):\n",
    "    \"\"\"\n",
    "    Trains the model\n",
    "    \"\"\"\n",
    "\n",
    "    from minio import Minio\n",
    "    import json\n",
    "    import shutil\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    os.environ['TORCH_HOME'] = '/tmp/models/'\n",
    "\n",
    "    minio_client = Minio(**minio_args)\n",
    "    minio_bucket = bucket_name\n",
    "    \n",
    "    def upload_directory(bucket_name, local_path, remote_prefix=\"\"):\n",
    "        for root, dirs, files in os.walk(local_path):\n",
    "            for file in files:\n",
    "                local_file_path = os.path.join(root, file)\n",
    "                remote_object_name = os.path.join(remote_prefix, os.path.relpath(local_file_path, local_path))\n",
    "                minio_client.fput_object(bucket_name, remote_object_name, local_file_path)\n",
    "\n",
    "\n",
    "    print(\"fetching data\")\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,\"data.zip\",\"/tmp/data.zip\")\n",
    "    shutil.unpack_archive(\"/tmp/data.zip\", \"/tmp/data/\", \"zip\")\n",
    "    \n",
    "    print(\"fetching code\")\n",
    "    minio_client.fget_object(minio_bucket,\"traincode.zip\",\"/tmp/traincode.zip\")\n",
    "    shutil.unpack_archive(\"/tmp/traincode.zip\", \"/tmp/code/\", \"zip\")\n",
    "    \n",
    "    print(\"training model\")\n",
    "    sys.path.insert(0, '/tmp/code')\n",
    "    from train import main\n",
    "    main()\n",
    "    \n",
    "    trainer_args = {\n",
    "        'epochs': no_epochs,\n",
    "        'profiler': 'pytorch',\n",
    "        'accelerator': accelerator,\n",
    "    }\n",
    "    \n",
    "    data_module_args = {\"train_num_workers\": 2}\n",
    "    \n",
    "    model_name=\"model.pth\"\n",
    "    checkpoint_dir=\"/tmp/checkpoints\"\n",
    "    tensorboard_root=\"/tmp/tensorboard\"\n",
    "    \n",
    "    train_output = main(\n",
    "        trainer_args=trainer_args,\n",
    "        tensorboard_root=tensorboard_root,\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        data_path=\"/tmp/data/\",\n",
    "        # mlpipeline_ui_metadata=\"mlpipeline-ui-metadata.json\",\n",
    "        # mlpipeline_metrics=\"mlpipeline-metrics.json\",\n",
    "        # results=\"results.json\",\n",
    "        # confusion_matrix_url=\"metrics\",\n",
    "        data_module_args=data_module_args\n",
    "    )\n",
    "\n",
    "    print(\"uploading model\")\n",
    "    minio_client.fput_object(minio_bucket,\"model.pt\",\"/tmp/model.pt\")\n",
    "    \n",
    "    print(\"uploading checkpoints\")\n",
    "    upload_directory(minio_bucket, checkpoint_dir, 'checkpoints')\n",
    "    \n",
    "    print(\"uploading tensorbord logs\")\n",
    "    upload_directory(minio_bucket, tensorboard_root, 'tensorboard')\n",
    "\n",
    "    print(\"Saved model to minIO\")\n",
    "    \n",
    "    return train_output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88e94d-3f2a-4104-bb32-2b8dbda61d2f",
   "metadata": {},
   "source": [
    "## Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8862de71-aa25-4095-be62-46836a25a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generation(minio_args, bucket_name, model_name):\n",
    "    \"\"\"\n",
    "    This can be used to convert model from one format to another \n",
    "    Here, we are creating a MAR file for serving\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    from minio import Minio\n",
    "    import json\n",
    "    import shutil\n",
    "    import os\n",
    "    import subprocess\n",
    "    \n",
    "    os.environ['TORCH_HOME'] = '/tmp/models/'\n",
    "\n",
    "    minio_client = Minio(**minio_args)\n",
    "    minio_bucket = bucket_name\n",
    "\n",
    "    print(\"getting model\")\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,\"model.pt\",\"/tmp/model.pt\")\n",
    "    \n",
    "    print(\"getting code\")\n",
    "    minio_client.fget_object(minio_bucket,\"convertcode.zip\",\"/tmp/convertcode.zip\")\n",
    "    shutil.unpack_archive(\"/tmp/convertcode.zip\", \"/tmp/code/\", \"zip\")\n",
    "    \n",
    "    print(\"converting model\")\n",
    "    bashCommand = f\"torch-model-archiver --model-name {model_name} --version 1.0 --serialized-file /tmp/model.pt --handler /tmp/code/ts/torch_handler/cifar34_handler.py --extra-files /tmp/code/index_to_name.json --export-path /tmp/\"\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    \n",
    "    print(\"uploading model\")\n",
    "    minio_client.fput_object(minio_bucket,f\"{model_name}/config/config.properties\",\"/tmp/code/config.properties\")\n",
    "    minio_client.fput_object(minio_bucket,f\"{model_name}/model-store/{model_name}.mar\",f\"/tmp/{model_name}.mar\")\n",
    "\n",
    "    print(\"Saved model to minIO\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ba3d5-9d5c-42c0-a449-7c3aba48becf",
   "metadata": {},
   "source": [
    "## Model Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fdd2e28-e979-4fc0-8754-80d53f8bfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_serving(bucket_name):\n",
    "    \"\"\"\n",
    "    Create kserve instance\n",
    "    \"\"\"\n",
    "    from kubernetes import client \n",
    "    from kserve import KServeClient\n",
    "    from kserve import constants\n",
    "    from kserve import utils\n",
    "    from kserve import V1beta1InferenceService\n",
    "    from kserve import V1beta1InferenceServiceSpec\n",
    "    from kserve import V1beta1PredictorSpec\n",
    "    from kserve import V1beta1TFServingSpec\n",
    "    from datetime import datetime\n",
    "\n",
    "    namespace = utils.get_default_target_namespace()\n",
    "\n",
    "    name='cifar34'\n",
    "    kserve_version='v1beta1'\n",
    "    api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
    "\n",
    "    isvc = V1beta1InferenceService(api_version=api_version,\n",
    "                                   kind=constants.KSERVE_KIND,\n",
    "                                   metadata=client.V1ObjectMeta(\n",
    "                                       name=name, namespace=namespace, annotations={'sidecar.istio.io/inject':'false'}),\n",
    "                                   spec=V1beta1InferenceServiceSpec(\n",
    "                                   predictor=V1beta1PredictorSpec(\n",
    "                                       service_account_name=\"sa-minio-kserve\",\n",
    "                                       pytorch=(V1beta1TFServingSpec(\n",
    "                                           storage_uri=f\"s3://bucket_name/cifar34/\"))))\n",
    "    )\n",
    "\n",
    "    KServe = KServeClient()\n",
    "    KServe.create(isvc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65f87a5-1dcf-449f-bf48-7e50757fa8c3",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393df630-8693-4f06-9590-e1d1dc9104e1",
   "metadata": {},
   "source": [
    "## Defining Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "913baff4-ce2d-4f0e-b7b1-9324858685e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_get_data = components.create_component_from_func(\n",
    "    func=get_data,\n",
    "    base_image=base_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32595f5a-2059-4403-ba69-3304816d4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_preprocess_data = components.create_component_from_func(\n",
    "    func=preprocess_data,\n",
    "    base_image=base_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76daa391-88b9-46f9-b370-216662098af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_model_training = components.create_component_from_func(\n",
    "    func=model_training,\n",
    "    base_image=base_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81891d00-5a97-41aa-9c98-6ee2a2e0c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_model_generation = components.create_component_from_func(\n",
    "    func=model_generation,\n",
    "    base_image=base_image,\n",
    "    packages_to_install=['torch-model-archiver==0.7.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd9d72a3-8062-428a-85f9-7f57a4ddad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_model_serving = components.create_component_from_func(\n",
    "    func=model_serving,\n",
    "    base_image=base_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f286d4-4fb2-4c40-80d5-e29454aa7f1c",
   "metadata": {},
   "source": [
    "## Defining Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03517465-fa26-4bcb-ba3e-ede6d149ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='pytorch-pipeline',\n",
    "    description='kubeflow pipeline'\n",
    ")\n",
    "def pipeline(no_epochs,accelerator,minio_args, bucket_name, model_name):\n",
    "    \n",
    "    volume_train = dsl.PipelineVolume(volume=k8s.client.V1Volume(            │\n",
    "│         name=\"shm\",                                                          │\n",
    "│         empty_dir=k8s.client.V1EmptyDirVolumeSource(medium='Memory'))) \n",
    "    \n",
    "    get_data = comp_get_data().set_display_name(\"Fetching Data\")\n",
    "    \n",
    "    preprocess_data = comp_preprocess_data(minio_args, bucket_name)\n",
    "    preprocess_data.after(get_data).set_display_name(\"Preprocessing Data\")\n",
    "    \n",
    "    model_training = comp_model_training(\n",
    "        no_epochs,accelerator, minio_args, bucket_name\n",
    "        ).after(preprocess_data\n",
    "                ).add_pvolumes({'/dev/shm': volume_train}\n",
    "                ).set_display_name(\"Training\"\n",
    "                ).set_memory_request('3000M'\n",
    "                ).set_memory_limit('3200M'\n",
    "                ).set_cpu_request('3000m'\n",
    "                ).set_cpu_limit('4000m'\n",
    "                ) \n",
    "    \n",
    "    model_generation = comp_model_generation(minio_args, bucket_name, model_name)\n",
    "    model_generation.after(model_training).set_display_name(\"MAR Generation\")\n",
    "\n",
    "    model_serving = comp_model_serving(minio_args, bucket_name, model_name)\n",
    "    model_serving.after(model_generation).set_display_name(\"Model Serving\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ee5f8-37cd-489f-b958-c84c7aa4b652",
   "metadata": {},
   "source": [
    "# Executing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a92e7e26-afe7-4fb2-b3b0-c4c64d9882c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/3e01f1c1-f656-4445-96e5-61ed0464a757\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/446e7d1f-9dfa-4584-985a-93ab0bbb3fee\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    client = kfp.Client()\n",
    "    current_datetime = datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    repo_url = \"https://github.com/exampleuser/example-repo.git\"\n",
    "    \n",
    "    bucket_name = \"pytorch\" + \"-\" + formatted_datetime\n",
    "    model_name = \"timm_vit\"\n",
    "\n",
    "    minio_args = {\n",
    "        \"url\": MINIO_URL,\n",
    "        \"user\": MINIO_USER,\n",
    "        \"pass\": MINIO_PASS,\n",
    "        \"secure\": MINIO_SECURE\n",
    "    }\n",
    "    \n",
    "    from minio import Minio\n",
    "    from minio.error import BucketAlreadyOwnedByYou\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        **minio_args\n",
    "    )\n",
    "    \n",
    "\n",
    "    try:\n",
    "        minio_client.make_bucket(bucket_name)\n",
    "        print(\"Bucket created successfully.\")\n",
    "    except BucketAlreadyOwnedByYou as e:\n",
    "        print(f\"Bucket '{e.bucket_name}' already exists and is owned by you.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating bucket: {e}\")  \n",
    "    \n",
    "    try:\n",
    "        subprocess.run([\"git\", \"clone\", repo_url, \"gitrepo\"], check=True)\n",
    "        print(f\"Repository cloned successfully to gitrepo\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to clone the repository. Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        \n",
    "    shutil.make_archive(\"traincode\", 'zip', \"gitrepo/traincode\")\n",
    "    shutil.make_archive(\"convertcode\", 'zip', \"gitrepo/convertcode\")\n",
    "        \n",
    "    minio_client.fput_object(bucket_name,\"traincode.zip\",\"./traincode.zip\")\n",
    "    minio_client.fput_object(bucket_name,\"convertcode.zip\",\"./convertcode.zip\")\n",
    "    \n",
    "    arguments = {\n",
    "        \"no_epochs\" : 1,\n",
    "        \"accelerator\": \"cpu\",\n",
    "        \"minio_args\": minio_args,\n",
    "        \"bucket_name\": bucket_name,\n",
    "        \"model_name\": model_name\n",
    "    }\n",
    "\n",
    "    experiment_name = \"default\"\n",
    "    run_directly = 1\n",
    "    \n",
    "    if (run_directly == 1):\n",
    "        client.create_run_from_pipeline_func(pipeline,arguments=arguments,experiment_name=experiment_name)\n",
    "    else:\n",
    "        kfp.compiler.Compiler().compile(pipeline_func=pipeline,package_path='output_test.yaml')\n",
    "        client.upload_pipeline_version(pipeline_package_path='output_test.yaml',pipeline_version_name=\"0.4\",pipeline_name=\"pipeline test\",description=\"just for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ea2e5-1c02-442b-b438-6275849c7773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff4c7bf-04aa-47c1-a3f3-c112a85ba2c3",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e77eb9cb-6b8d-4e42-a813-a0c6abbda17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kubernetes import client \n",
    "from kserve import KServeClient\n",
    "from kserve import constants\n",
    "from kserve import utils\n",
    "from kserve import V1beta1InferenceService\n",
    "from kserve import V1beta1InferenceServiceSpec\n",
    "from kserve import V1beta1PredictorSpec\n",
    "from kserve import V1beta1SKLearnSpec\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e61d921-0e0c-49de-95d6-4e4237320481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"cifar34\", \"ready\": true}"
     ]
    }
   ],
   "source": [
    "!curl http://cifar34.kubeflow-user-example-com.svc.cluster.local/v1/models/cifar34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf107f1a-5ccc-49b9-bf57-2b3cc5114f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 11013  100 11013    0     0  30762      0 --:--:-- --:--:-- --:--:-- 30762\n"
     ]
    }
   ],
   "source": [
    "!curl -LO https://github.com/mmg10/ptkflow/raw/main/153.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3868d106-a936-4157-81ee-fba36b8c3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_domain = 'http://cifar34.kubeflow-user-example-com.svc.cluster.local'\n",
    "model_name='cifar34'\n",
    "service_url = f'{actual_domain}/v1/models/{model_name}:predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10bdded3-d63d-4096-b91f-3ce827664281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "image = open('153.jpg', 'rb') #open binary file in read mode\n",
    "image_read = image.read()\n",
    "image_64_encode = base64.b64encode(image_read)\n",
    "bytes_array = image_64_encode.decode('utf-8')\n",
    "request = {\n",
    "  \"instances\":[\n",
    "    {\n",
    "      \"data\": bytes_array\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9671ccb-d619-4d84-b887-10a33dc02928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'mountain': 0.48141807317733765, 'sea': 0.27487021684646606, 'glacier': 0.1335740089416504, 'buildings': 0.06491722911596298, 'street': 0.0399005189538002}]}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(service_url, json=request)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130df1e-1dcb-4ada-a9eb-f2eee93d3ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
